{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week1-exercise",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliakbarbadri/nlp-tf/blob/master/week2/week2-examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQM0KGAd4atk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import io\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af_0QtuOG5G9",
        "colab_type": "text"
      },
      "source": [
        "# Lesson 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axAaI91ADgFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-9x5kDeDqol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsTpo7N1GMZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sents = []\n",
        "train_labels = []\n",
        "test_sents = []\n",
        "test_labels = []\n",
        "\n",
        "for s,l in train_data:\n",
        "  train_sents.append(str(s.numpy()))\n",
        "  train_labels.append(l.numpy())\n",
        "\n",
        "for s,l in test_data:\n",
        "  test_sents.append(str(s.numpy()))\n",
        "  test_labels.append(l.numpy())\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--KsZXjhGwN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "max_len = 120\n",
        "trunc_type = \"post\"\n",
        "oov_token = \"<OOV>\"\n",
        "embedding_dim = 16\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(train_sents)\n",
        "train_word_index = tokenizer.word_index\n",
        "train_seqs = tokenizer.texts_to_sequences(train_sents)\n",
        "train_padded = pad_sequences(train_seqs,maxlen=max_len, truncating=trunc_type)\n",
        "\n",
        "test_seqs = tokenizer.texts_to_sequences(test_sents)\n",
        "test_padded = pad_sequences(test_seqs,maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD7xhf-NKTlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5f339764-8303-4d11-e060-47c6549524fb"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 11526     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 171,533\n",
            "Trainable params: 171,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBKz6H5WvdVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e63b76eb-0744-43f0-ba7d-1bcc63946690"
      },
      "source": [
        "model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4994 - accuracy: 0.7345 - val_loss: 0.3579 - val_accuracy: 0.8420\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2456 - accuracy: 0.9026 - val_loss: 0.3675 - val_accuracy: 0.8381\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.1014 - accuracy: 0.9732 - val_loss: 0.4466 - val_accuracy: 0.8274\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0264 - accuracy: 0.9964 - val_loss: 0.5191 - val_accuracy: 0.8278\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5838 - val_accuracy: 0.8273\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.8303\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 9.0598e-04 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8301\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 4.8210e-04 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.8303\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 3.9115e-04 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.8285\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.7235e-04 - accuracy: 1.0000 - val_loss: 0.7982 - val_accuracy: 0.8294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1692b01080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lml4JsXvjhFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e221cd1e-3596-4502-9577-0783be0cc414"
      },
      "source": [
        "weights = model.layers[0].get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEyGMZLTCcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a3bbb287-e2b7-4776-cfbe-dda9eb62ed70"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in train_word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "print(train_padded[1])\n",
        "print(decode_review(train_padded[1]))\n",
        "print(train_sents[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0  256   28   78  585    6  815 2383\n",
            "  317  109   19   12    7  643  696    6    4 2249    5  183  599   68\n",
            " 1483  114 2289    3 4005   22    2    1    3  263   43 4754    4  173\n",
            "  190   22   12 4126   11 1604 2383   87    2   20   14 1945    2  115\n",
            "  950   14 1838 1367  563    3  365  183  477    6  602   19   17   61\n",
            " 1845    5   51   14 4090   98   42  138   11  983   11  200   28 1059\n",
            "  171    5    2   20   19   11  298    2 2182    5   10    3  285   43\n",
            "  477    6  602    5   94  203    1  206  102  148 4450   16  228  336\n",
            "   11 2510  392   12   20   32   31   47]\n",
            "? ? ? ? ? ? ? b'i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the <OOV> and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own <OOV> without any real concern for anything else i cant recommend this film at all '\n",
            "b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B28-BhdwjcfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors_file = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "words_file = io.open('words.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  words_file.write(word + \"\\n\")\n",
        "  vectors_file.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "vectors_file.close()\n",
        "words_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKouKG0a7QFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"vectors.tsv\")\n",
        "files.download(\"words.tsv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}